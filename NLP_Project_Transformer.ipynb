{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "_ARrWkh0cgT5",
        "outputId": "ec865619-fd10-4ca7-e92b-b0f82627e457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.9.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "id": "2-8djzhrgh8G",
        "outputId": "8d3c6d5b-1d2d-4b16-bd34-553c5f3bcfb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp38-cp38-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6SdTx2s8L4u",
        "outputId": "78207eb8-6fb9-4fcc-fb5c-1aa48bfd7904"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.6.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "import matplotlib.pyplot as plt\n",
        "import sacrebleu"
      ],
      "metadata": {
        "id": "xE0mecsoczUF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE = 'de' # for code\n",
        "TGT_LANGUAGE = 'en' # for comments\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ],
      "metadata": {
        "id": "BO3AERTec276"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "Mr0XdBzhdGrV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
      ],
      "metadata": {
        "id": "PjJxk1ZvdMDQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_data = pd.read_csv(\"/content/drive/MyDrive/python_dataset.csv\")\n",
        "Test_data = pd.read_excel(\"/content/drive/MyDrive/python_test_dataset.xlsx\")"
      ],
      "metadata": {
        "id": "jpT-EiipuHB4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_data = Train_data[:10000] # taking only 10000 rows from approximately 600000 rows, cause then it will take too long to train"
      ],
      "metadata": {
        "id": "Poc9dgwUvAps"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KtNvYjIW1cRA",
        "outputId": "dd29def3-ca17-474c-f45f-601040a6b6f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               code  \\\n",
              "0           0        sorted(l, key=lambda x: (-int(x[1]), x[0]))   \n",
              "1           1                         [int(x) for x in str(num)]   \n",
              "2           2                         c.decode('unicode_escape')   \n",
              "3           3  parser.add_argument('-t', dest='table', help='...   \n",
              "4           4  datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:...   \n",
              "\n",
              "                                           docstring  \n",
              "0                 Sort a nested list by two elements  \n",
              "1               converting integer to list in python  \n",
              "2           Converting byte string in unicode string  \n",
              "3                    List of arguments with argparse  \n",
              "4  How to convert a Date string to a DateTime obj...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-964b23a4-4494-41f4-854a-027287e4afe7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>code</th>\n",
              "      <th>docstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sorted(l, key=lambda x: (-int(x[1]), x[0]))</td>\n",
              "      <td>Sort a nested list by two elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[int(x) for x in str(num)]</td>\n",
              "      <td>converting integer to list in python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>c.decode('unicode_escape')</td>\n",
              "      <td>Converting byte string in unicode string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>parser.add_argument('-t', dest='table', help='...</td>\n",
              "      <td>List of arguments with argparse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:...</td>\n",
              "      <td>How to convert a Date string to a DateTime obj...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-964b23a4-4494-41f4-854a-027287e4afe7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-964b23a4-4494-41f4-854a-027287e4afe7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-964b23a4-4494-41f4-854a-027287e4afe7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_code = Train_data['code'].to_numpy()\n",
        "Train_comment = Train_data['docstring'].to_numpy()\n",
        "Train_code_comment = []\n",
        "\n",
        "Test_code = Test_data['code'].to_numpy()\n",
        "Test_comment = Test_data['docstring'].to_numpy()\n",
        "Test_code_comment = []"
      ],
      "metadata": {
        "id": "jFUu3TO3vNNN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Train_code)):\n",
        "    Train_code[i] = str(Train_code[i])\n",
        "    Train_comment[i] = str(Train_comment[i])\n",
        "\n",
        "for i in range(len(Test_code)):\n",
        "    Test_code[i] = str(Test_code[i])\n",
        "    Test_comment[i] = str(Test_comment[i])"
      ],
      "metadata": {
        "id": "Lqy975Ee2x4h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Train_code)):\n",
        "    Train_code_comment.append((Train_code[i], Train_comment[i]))\n",
        "\n",
        "for i in range(len(Test_code)):\n",
        "    Test_code_comment.append((Test_code[i], Test_comment[i]))"
      ],
      "metadata": {
        "id": "7e9C_3spvufr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train_iterator = iter(Train_code_comment)\n",
        "# Test_iterator = iter(Test_code_comment)"
      ],
      "metadata": {
        "id": "7JFVRsBpxRiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    train_iter = Train_code_comment\n",
        "\n",
        "    # Create torchtext's Vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)"
      ],
      "metadata": {
        "id": "0nRTa4K9eKsN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "KQMdXIYDd6wu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RWj88DMTcV2K"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network \n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PG4vr1FacV2M"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "s2F_Gwo2cV2N"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u4YRbKRKcV2O"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gFnk88Y2cV2Q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = Train_code_comment\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    \n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Test_code_comment\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        \n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AprQkCe8cV2R",
        "outputId": "900e84d8-8ddf-4ac6-f33b-826a5a3a800d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 4.678, Val loss: 4.145, Epoch time = 16.071s\n",
            "Epoch: 2, Train loss: 3.894, Val loss: 3.722, Epoch time = 15.928s\n",
            "Epoch: 3, Train loss: 3.583, Val loss: 3.495, Epoch time = 16.033s\n",
            "Epoch: 4, Train loss: 3.359, Val loss: 3.273, Epoch time = 16.204s\n",
            "Epoch: 5, Train loss: 3.165, Val loss: 3.071, Epoch time = 17.280s\n",
            "Epoch: 6, Train loss: 2.987, Val loss: 2.876, Epoch time = 16.215s\n",
            "Epoch: 7, Train loss: 2.820, Val loss: 2.724, Epoch time = 16.129s\n",
            "Epoch: 8, Train loss: 2.663, Val loss: 2.555, Epoch time = 16.178s\n",
            "Epoch: 9, Train loss: 2.508, Val loss: 2.426, Epoch time = 16.139s\n",
            "Epoch: 10, Train loss: 2.362, Val loss: 2.263, Epoch time = 16.133s\n",
            "Epoch: 11, Train loss: 2.222, Val loss: 2.122, Epoch time = 16.136s\n",
            "Epoch: 12, Train loss: 2.090, Val loss: 1.977, Epoch time = 16.188s\n",
            "Epoch: 13, Train loss: 1.964, Val loss: 1.835, Epoch time = 16.192s\n",
            "Epoch: 14, Train loss: 1.838, Val loss: 1.741, Epoch time = 16.335s\n",
            "Epoch: 15, Train loss: 1.722, Val loss: 1.634, Epoch time = 16.154s\n",
            "Epoch: 16, Train loss: 1.613, Val loss: 1.599, Epoch time = 16.101s\n",
            "Epoch: 17, Train loss: 1.506, Val loss: 1.467, Epoch time = 17.393s\n",
            "Epoch: 18, Train loss: 1.409, Val loss: 1.357, Epoch time = 16.183s\n",
            "Epoch: 19, Train loss: 1.312, Val loss: 1.248, Epoch time = 16.110s\n",
            "Epoch: 20, Train loss: 1.226, Val loss: 1.152, Epoch time = 16.060s\n",
            "Epoch: 21, Train loss: 1.148, Val loss: 1.133, Epoch time = 16.056s\n",
            "Epoch: 22, Train loss: 1.071, Val loss: 1.039, Epoch time = 16.078s\n",
            "Epoch: 23, Train loss: 1.000, Val loss: 1.001, Epoch time = 16.189s\n",
            "Epoch: 24, Train loss: 0.937, Val loss: 0.952, Epoch time = 16.117s\n",
            "Epoch: 25, Train loss: 0.880, Val loss: 0.919, Epoch time = 16.089s\n",
            "Epoch: 26, Train loss: 0.823, Val loss: 0.883, Epoch time = 16.154s\n",
            "Epoch: 27, Train loss: 0.774, Val loss: 0.883, Epoch time = 16.171s\n",
            "Epoch: 28, Train loss: 0.724, Val loss: 0.842, Epoch time = 17.330s\n",
            "Epoch: 29, Train loss: 0.687, Val loss: 0.810, Epoch time = 16.159s\n",
            "Epoch: 30, Train loss: 0.647, Val loss: 0.825, Epoch time = 16.077s\n",
            "Epoch: 31, Train loss: 0.613, Val loss: 0.792, Epoch time = 16.150s\n",
            "Epoch: 32, Train loss: 0.581, Val loss: 0.793, Epoch time = 16.178s\n",
            "Epoch: 33, Train loss: 0.553, Val loss: 0.772, Epoch time = 16.275s\n",
            "Epoch: 34, Train loss: 0.526, Val loss: 0.770, Epoch time = 16.189s\n",
            "Epoch: 35, Train loss: 0.503, Val loss: 0.764, Epoch time = 16.229s\n",
            "Epoch: 36, Train loss: 0.484, Val loss: 0.766, Epoch time = 16.172s\n",
            "Epoch: 37, Train loss: 0.467, Val loss: 0.749, Epoch time = 16.170s\n",
            "Epoch: 38, Train loss: 0.448, Val loss: 0.772, Epoch time = 16.202s\n",
            "Epoch: 39, Train loss: 0.433, Val loss: 0.767, Epoch time = 17.234s\n",
            "Epoch: 40, Train loss: 0.419, Val loss: 0.710, Epoch time = 16.173s\n",
            "Epoch: 41, Train loss: 0.406, Val loss: 0.718, Epoch time = 16.140s\n",
            "Epoch: 42, Train loss: 0.395, Val loss: 0.725, Epoch time = 16.128s\n",
            "Epoch: 43, Train loss: 0.382, Val loss: 0.739, Epoch time = 16.157s\n",
            "Epoch: 44, Train loss: 0.370, Val loss: 0.719, Epoch time = 16.221s\n",
            "Epoch: 45, Train loss: 0.361, Val loss: 0.754, Epoch time = 16.218s\n",
            "Epoch: 46, Train loss: 0.355, Val loss: 0.728, Epoch time = 16.099s\n",
            "Epoch: 47, Train loss: 0.347, Val loss: 0.718, Epoch time = 16.194s\n",
            "Epoch: 48, Train loss: 0.335, Val loss: 0.732, Epoch time = 16.264s\n",
            "Epoch: 49, Train loss: 0.330, Val loss: 0.706, Epoch time = 16.253s\n",
            "Epoch: 50, Train loss: 0.324, Val loss: 0.687, Epoch time = 17.284s\n"
          ]
        }
      ],
      "source": [
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    train_loss_list.append(train_loss)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    val_loss_list.append(val_loss)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "    # print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "\n",
        "# function to generate output sequence using greedy algorithm \n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = [i for i in range(NUM_EPOCHS)]\n",
        "plt.plot(x_axis, train_loss_list, label=\"training Loss\")\n",
        "plt.plot(x_axis, val_loss_list, label=\"validation Loss\")\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"CrossEntropyLoss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "HZSIwGu6Czu6",
        "outputId": "fe10ce2a-e5c9-470d-90ef-19db3dedf670"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Va1xaQjJcV2S",
        "outputId": "0dcbe574-159b-4a57-d48e-e988dd055f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " converting integer to list in python \n"
          ]
        }
      ],
      "source": [
        "print(translate(transformer, \"[int(x) for x in str(num)]\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(transformer, \"if (num % i) == 0:\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSjAuVz6NExv",
        "outputId": "0c9677e4-08a9-4caf-e500-e9c0e686f04d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " How to perform if one of the same zero ? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(transformer, Test_code_comment[11][0]))\n",
        "print(Test_code_comment[11][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYKn1pjRLNVA",
        "outputId": "7aa1b2e1-cee6-4669-c7b3-95227701a3c5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Python splitting string by parentheses \n",
            "Python splitting string by parentheses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_bleu_score = 0\n",
        "diff = 0\n",
        "for i in range(len(Test_code_comment)):\n",
        "    pred = translate(transformer, Test_code_comment[i][0])\n",
        "    bleu_score = (sacrebleu.sentence_bleu(pred, [Test_code_comment[i][1]], smooth_method='exp')).score\n",
        "    print(bleu_score)\n",
        "    total_bleu_score += bleu_score\n",
        "    # if(bleu_score==0):\n",
        "    #     diff += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isuo12EMAtLa",
        "outputId": "a90f2e4e-97b7-4269-ab06-63c93a93ace3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "21.200626759025184\n",
            "100.00000000000004\n",
            "71.02992180127417\n",
            "23.462350320528007\n",
            "0.0\n",
            "100.00000000000004\n",
            "76.26264731696685\n",
            "45.180100180492246\n",
            "100.00000000000004\n",
            "87.0239763769791\n",
            "100.00000000000004\n",
            "5.815868174415823\n",
            "86.6877899750182\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "73.61703354503862\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "13.485111859503691\n",
            "5.693025330278465\n",
            "81.93228857188173\n",
            "81.93228857188173\n",
            "81.93228857188173\n",
            "100.00000000000004\n",
            "8.170609724417774\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "75.77395672414198\n",
            "6.722636787666482\n",
            "33.18077402843942\n",
            "61.62607099729587\n",
            "100.00000000000004\n",
            "4.767707020457095\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "3.7477767366779213\n",
            "0.0\n",
            "0.0\n",
            "4.196114906296549\n",
            "4.8734989388136185\n",
            "4.79981069911921\n",
            "0.0\n",
            "0.0\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "6.8803707079889325\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "80.71177470053898\n",
            "0.0\n",
            "2.9859662827819125\n",
            "17.491650626361256\n",
            "8.745825313180626\n",
            "15.619699684601276\n",
            "7.347053125977879\n",
            "36.55552228545123\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "79.39226578179516\n",
            "4.990049701936832\n",
            "49.202745153855076\n",
            "7.593603555191143\n",
            "100.00000000000004\n",
            "6.742555929751843\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "44.95431954509448\n",
            "57.83569866465144\n",
            "0.0\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "5.679677445135579\n",
            "100.00000000000004\n",
            "3.056960239296902\n",
            "76.5928338364649\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "4.767707020457095\n",
            "100.00000000000004\n",
            "100.00000000000004\n",
            "7.347053125977879\n",
            "7.417318111314057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total test bleu score = {total_bleu_score/(len(Test_code_comment)-diff):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqIeCt4bQkdq",
        "outputId": "bf21da38-7fa2-43cb-e21b-302138898ad1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total test bleu score = 62.5760\n"
          ]
        }
      ]
    }
  ]
}